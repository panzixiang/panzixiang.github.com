---
layout: post
title: "Week 3 Parameter estimation"
description: ""
category: 
tags: []
---
{% include JB/setup %}

## GDELT Column data aggregation and transformation

We are separating the treatment of event metadata and event impact to generate a map of metadata and and real number quantifying the impact of the event.

### Metadata aggregation

We are aggregating the data rows first by country and then by ActorType1Code and deriving a time series out of them. Each Type will be a regressor and each country will be a vector of types to be fed into VAR. The countries we choose will be the country pair of the exchange rate (for now) and we are assigning different codes to international organizations (UN, EU, NATO etc) to that they have an entity representation.

#### Sample results

USA_20050101 (Country and date)

|Column                | Positive impact  | Negative impact |
|:---------------------|:-----------------|:----------------|
|BUS (business)        | +50              |-20              |    
|GOV (government)      | +10              |-15              |
|...                   |                  |                 |

...

GBR_20050101 (Country and date)

|Column                | Positive impact  | Negative impact |
|:---------------------|:-----------------|:----------------|
|BUS (business)        | +10              |-20              |    
|GOV (government)      | +40              |-15              |
|...                   |                  |                 |

THe numbers in the impact columns represent the relative impact generated by the event according to our impact heuristic function.


### Impact heuristic function

We try out a few heuristic functions to map categorical variables onto the real line. The general idea is that we are attenuating the intrinsic type of the event by the number of mentions (articles sources etc.) and we hope that it is immediately verifiable.

#### first heuristic

$$ H_1 = NumArticles \times GoldSteinScale $$

Preliminaries show no linear relationship between regressors and predictors.

#### second heuristic

$$ H_2 = NumArticles \times AvgTone $$

#### third heuristic

$$ H_3 = NumArticles \times QuadClass $$


## Classification

### Binary Classification on the Change in Daily Forex Rates
The financial instrument that we look at is the foreign exchange rate between British Pounds (GBP) and American Dollars (USD). We attempt to use the GDELT news data up to day $$ T $$ to infer whether prices will go up or go down between day $$ T - 1 $$ and day $$ T $$. The daily return in exchange rate is calculated as:

$$ r_T = \frac{P_T} {P_{T-1}} - 1 $$

where $$ P_T $$ is the exchange rate of day $$ T $$


We use the GBP-USD exchange rates and the GDELT dataset from 2005. Below is the distribution of daily returns of the exchange rates for 2005:

<center><img src="/assets/week_3/DailyReturnHistogram.png" width="100%"></center>

We treat all returns that exceed 0.5% as positive labels and returns that are below -0.5% as negative labels. This give us 75 positive labels and 90 negative labels which form 165 data points in total. We randomly select 70% of the data points as training data and the
remaining 30% as test data. The experiment is repeated 100 times for each heuristic.

The table below shows the classification accuracy of running SVM with the different heuristics on the test set:

|Heuristic                | Linear Kernel  | Other Kernels (TBD) |
|:------------------------|:-----------------|:----------------|
|$$ H_1 = NumArticles \times GoldSteinScale $$ | 51.0%   |      |    
|$$ H_2 = NumArticles \times AvgTone $$        | 58.4%   |      |
|$$ H_3 = NumArticles \times QuadClass $$      | 55.9%   |      |




